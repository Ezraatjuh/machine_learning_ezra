{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapting datasets to be interpreted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = pd.read_csv(\"data/ais_train.csv\", delimiter='|')\n",
    "X_sample.to_csv('data/ais_train_modified.csv', index=False)\n",
    "extra_vessels = pd.read_csv(\"data/vessels.csv\", on_bad_lines='skip', delimiter='|')\n",
    "extra_vessels.to_csv('data/vessels_modified.csv', index=False)\n",
    "extra_ports = pd.read_csv(\"data/ports.csv\", on_bad_lines='skip', delimiter='|')\n",
    "extra_ports.to_csv('data/ports_modified.csv', index=False)\n",
    "extra_schedules = pd.read_csv(\"data/schedules_to_may_2024.csv\", on_bad_lines='skip', delimiter='|')\n",
    "extra_schedules.to_csv('data/schedules_to_may_2024_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_evaluation = pd.read_csv(\"data/ais_test.csv\",)\n",
    "extra_ports = pd.read_csv(\"data/ports_modified.csv\")\n",
    "extra_vessels = pd.read_csv(\"data/vessels_modified.csv\")\n",
    "extra_schedules = pd.read_csv(\"data/schedules_to_may_2024_modified.csv\")\n",
    "X_original = pd.read_csv(\"data/ais_train_modified.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing current data into previous data for the train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def past_course(original):\n",
    "    original=original.reset_index()\n",
    "\n",
    "    original['prev_lat'] = original['latitude'].shift(1).fillna(original['latitude'].iloc[0])\n",
    "    original['prev_lon'] = original['longitude'].shift(1).fillna(original['longitude'].iloc[0])\n",
    "    original['time_2'] = original['time'].shift(1).fillna(original['time'].iloc[0])\n",
    "    original['cog'] = original['cog'].shift(1)\n",
    "    original['sog'] = original['sog'].shift(1)\n",
    "    original['rot'] = original['rot'].shift(1)\n",
    "    original['heading'] = original['heading'].shift(1)\n",
    "    original['navstat'] = original['navstat'].shift(1)\n",
    "    original.loc[0,['cog','sog','rot','heading','navstat']]=[0,0,0,0,0]\n",
    "\n",
    "    return original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapting_training_data(original):\n",
    "    unique = original['vesselId'].unique()\n",
    "    new = original.copy()\n",
    "    new['time'] = pd.to_datetime(new['time'])\n",
    "    new['prev_lat']=original['latitude']\n",
    "    new['prev_lon']=original['longitude']\n",
    "    new['time_2'] = new['time']\n",
    "    new = new.reset_index()\n",
    "    final = pd.DataFrame(columns=new.columns)\n",
    "    for c in unique:\n",
    "        filtered = new[new['vesselId'] == c].copy()\n",
    "        new_filtered = past_course(filtered)\n",
    "        final = pd.concat([final, new_filtered], ignore_index=True)\n",
    "    final = final.sort_values(by='index')\n",
    "    final = final.drop(['index'],axis=1)\n",
    "    final = final.reset_index(drop=True)\n",
    "    final = final.drop(['level_0'],axis=1)\n",
    "    return(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtlas\\AppData\\Local\\Temp\\ipykernel_7140\\561889474.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final = pd.concat([final, new_filtered], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "testeo = new_dataframe(X_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cog</th>\n",
       "      <th>sog</th>\n",
       "      <th>rot</th>\n",
       "      <th>heading</th>\n",
       "      <th>navstat</th>\n",
       "      <th>etaRaw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>portId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 00:00:25</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>01-09 23:00</td>\n",
       "      <td>-34.74370</td>\n",
       "      <td>-57.85130</td>\n",
       "      <td>61e9f3a8b937134a3c4bfdf7</td>\n",
       "      <td>61d371c43aeaecc07011a37f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 00:00:36</td>\n",
       "      <td>109.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6</td>\n",
       "      <td>347</td>\n",
       "      <td>1</td>\n",
       "      <td>12-29 20:00</td>\n",
       "      <td>8.89440</td>\n",
       "      <td>-79.47939</td>\n",
       "      <td>61e9f3d4b937134a3c4bff1f</td>\n",
       "      <td>634c4de270937fc01c3a7689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 00:01:45</td>\n",
       "      <td>111.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>01-02 09:00</td>\n",
       "      <td>39.19065</td>\n",
       "      <td>-76.47567</td>\n",
       "      <td>61e9f436b937134a3c4c0131</td>\n",
       "      <td>61d3847bb7b7526e1adf3d19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 00:03:11</td>\n",
       "      <td>96.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>12-31 20:00</td>\n",
       "      <td>-34.41189</td>\n",
       "      <td>151.02067</td>\n",
       "      <td>61e9f3b4b937134a3c4bfe77</td>\n",
       "      <td>61d36f770a1807568ff9a126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 00:03:51</td>\n",
       "      <td>214.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>01-25 12:00</td>\n",
       "      <td>35.88379</td>\n",
       "      <td>-5.91636</td>\n",
       "      <td>61e9f41bb937134a3c4c0087</td>\n",
       "      <td>634c4de270937fc01c3a74f3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time    cog   sog  rot  heading  navstat       etaRaw  \\\n",
       "0  2024-01-01 00:00:25  284.0   0.7    0       88        0  01-09 23:00   \n",
       "1  2024-01-01 00:00:36  109.6   0.0   -6      347        1  12-29 20:00   \n",
       "2  2024-01-01 00:01:45  111.0  11.0    0      112        0  01-02 09:00   \n",
       "3  2024-01-01 00:03:11   96.4   0.0    0      142        1  12-31 20:00   \n",
       "4  2024-01-01 00:03:51  214.0  19.7    0      215        0  01-25 12:00   \n",
       "\n",
       "   latitude  longitude                  vesselId                    portId  \n",
       "0 -34.74370  -57.85130  61e9f3a8b937134a3c4bfdf7  61d371c43aeaecc07011a37f  \n",
       "1   8.89440  -79.47939  61e9f3d4b937134a3c4bff1f  634c4de270937fc01c3a7689  \n",
       "2  39.19065  -76.47567  61e9f436b937134a3c4c0131  61d3847bb7b7526e1adf3d19  \n",
       "3 -34.41189  151.02067  61e9f3b4b937134a3c4bfe77  61d36f770a1807568ff9a126  \n",
       "4  35.88379   -5.91636  61e9f41bb937134a3c4c0087  634c4de270937fc01c3a74f3  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = testeo[testeo['vesselId'] == '61e9f3a8b937134a3c4bfdf7'].copy()\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travel_predict(lon,lat,speed, time, direction):\n",
    "    speed = speed *0.514444*3600\n",
    "    dist = (speed * time)/1000\n",
    "    lat = lat * (math.pi/180)\n",
    "    lon = lon * (math.pi/180)\n",
    "    direction = direction * (math.pi/180)\n",
    "    R=6371\n",
    "    latf = math.asin(math.sin(lat)*math.cos(dist/R) + math.cos(lat)*math.sin(dist/R)*math.cos(direction))\n",
    "    lonf = lon + math.atan((math.sin(direction)*math.sin(dist/R)*math.cos(lat))/(math.cos(dist/R)-(math.sin(lat)*math.sin(latf))))\n",
    "    latf = latf*(180/math.pi)\n",
    "    lonf = lonf*(180/math.pi)\n",
    "    return (lonf,latf)\n",
    "def travel_predict_1(df):\n",
    "    lat = df['prev_lat'] * (np.pi / 180)\n",
    "    lon = df['prev_lon'] * (np.pi / 180)\n",
    "    speed = df['sog'] * 0.514444 * 3600\n",
    "    dist = (speed * df['time_dif']) / 1000\n",
    "    direction = df['cog'] * (np.pi / 180)\n",
    "    R = 6371\n",
    "\n",
    "    latf = np.arcsin(np.sin(lat) * np.cos(dist / R) + np.cos(lat) * np.sin(dist / R) * np.cos(direction))\n",
    "    lonf = lon + np.arctan((np.sin(direction) * np.sin(dist / R) * np.cos(lat)) /(np.cos(dist / R) - (np.sin(lat) * np.sin(latf))))\n",
    "\n",
    "    latf = latf * (180 / np.pi)\n",
    "    lonf = lonf * (180 / np.pi)\n",
    "\n",
    "    result = pd.DataFrame({'longitude_predicted': lonf, 'latitude_predicted': latf})\n",
    "\n",
    "    return result\n",
    "\n",
    "def adapting_test_data (evaluation,training):\n",
    "    evalu=evaluation.copy()\n",
    "    evalu['time'] = pd.to_datetime(evalu['time'])\n",
    "    evalu['time_2'] = evalu['time']\n",
    "    evalu['cog'] = 0.1\n",
    "    evalu['sog'] = 0.1\n",
    "    evalu['heading'] = 0.1\n",
    "    evalu['navstat'] = 0.1\n",
    "    evalu['etaRaw'] = evalu['time']\n",
    "    evalu['latitude'] = 0.11111111\n",
    "    evalu['longitude'] = 0.11111111\n",
    "    evalu['portId'] ='61d371c43aeaecc07011a37f'\n",
    "    train=training.copy()\n",
    "    train['time'] = pd.to_datetime(train['time'])\n",
    "    train['time_2'] = train['time']\n",
    "    evalu = evalu.drop(['ID','scaling_factor'],axis=1)\n",
    "    final = pd.concat([train, evalu], ignore_index=True)\n",
    "    x =new_dataframe(final)\n",
    "    evalu = x.iloc[len(train):]\n",
    "    unique = evalu['vesselId'].unique()\n",
    "    final = final.iloc[0:0]\n",
    "    for c in unique:\n",
    "        filtered = evalu[evalu['vesselId'] == c].copy()\n",
    "        filtered = filtered.reset_index()\n",
    "        filtered[['time_2','cog','sog','rot','heading','navstat','etaRaw','prev_lat','prev_lon']] = filtered.iloc[0][['time_2','cog','sog','rot','heading','navstat','etaRaw','prev_lat','prev_lon']]\n",
    "        final = pd.concat([final,filtered], ignore_index=True)\n",
    "    final['time_dif'] = (final['time']-final['time_2']).dt.total_seconds()/3600\n",
    "    final = final.sort_values(by='index')\n",
    "    final = final.drop(['index'],axis=1)\n",
    "    final = final.reset_index(drop=True)\n",
    "    #final = final.drop(['level_0'],axis=1)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #   pred = evaluation.copy()\n",
    "  #  pred = pred.drop(['vesselId','time','scaling_factor'],axis=1)\n",
    "   # pred['longitude_predicted']=0\n",
    "   # pred['latitude_predicted']=0\n",
    "t = assignation(X_evaluation,X_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.copy()\n",
    "x = x.drop(['latitude','longitude','time_2','prev_lat','prev_lon','time_dif','vesselId','portId'],axis=1)\n",
    "x['time'] = pd.to_datetime(x['time'])\n",
    "x['year'] = x['time'].dt.year\n",
    "x['month'] = x['time'].dt.month\n",
    "x['day'] = x['time'].dt.day\n",
    "x['hour'] = x['time'].dt.hour\n",
    "x['minute'] = x['time'].dt.minute\n",
    "x['second'] = x['time'].dt.second\n",
    "\n",
    "x['etaRaw'] = pd.to_datetime(x['etaRaw'], format='%m-%d %H:%M', errors='coerce')\n",
    "x['eta_month'] = x['etaRaw'].dt.month\n",
    "x['eta_day'] = x['etaRaw'].dt.day\n",
    "x['eta_hour'] = x['etaRaw'].dt.hour\n",
    "x['eta_minute'] = x['etaRaw'].dt.minute\n",
    "\n",
    "x = x.drop(['time','etaRaw'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cog</th>\n",
       "      <th>sog</th>\n",
       "      <th>rot</th>\n",
       "      <th>heading</th>\n",
       "      <th>navstat</th>\n",
       "      <th>etaRaw</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>vesselId</th>\n",
       "      <th>portId</th>\n",
       "      <th>time_2</th>\n",
       "      <th>prev_lat</th>\n",
       "      <th>prev_lon</th>\n",
       "      <th>time_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-08 00:03:16</td>\n",
       "      <td>179.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-05-08 00:03:16</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>61e9f3aeb937134a3c4bfe3d</td>\n",
       "      <td>61d371c43aeaecc07011a37f</td>\n",
       "      <td>2024-05-07 23:48:16</td>\n",
       "      <td>31.14647</td>\n",
       "      <td>-81.49789</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-08 00:06:17</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2024-05-08 00:06:17</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>61e9f473b937134a3c4c02df</td>\n",
       "      <td>61d371c43aeaecc07011a37f</td>\n",
       "      <td>2024-05-07 23:57:16</td>\n",
       "      <td>14.81694</td>\n",
       "      <td>120.29625</td>\n",
       "      <td>0.150278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-08 00:10:02</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2024-05-08 00:10:02</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>61e9f469b937134a3c4c029b</td>\n",
       "      <td>61d371c43aeaecc07011a37f</td>\n",
       "      <td>2024-05-07 23:59:08</td>\n",
       "      <td>38.27895</td>\n",
       "      <td>10.78280</td>\n",
       "      <td>0.181667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-05-08 00:10:34</td>\n",
       "      <td>321.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2024-05-08 00:10:34</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>61e9f45bb937134a3c4c0221</td>\n",
       "      <td>61d371c43aeaecc07011a37f</td>\n",
       "      <td>2024-05-07 23:52:34</td>\n",
       "      <td>-43.53785</td>\n",
       "      <td>172.83522</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-05-08 00:12:27</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2024-05-08 00:12:27</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>61e9f38eb937134a3c4bfd8d</td>\n",
       "      <td>61d371c43aeaecc07011a37f</td>\n",
       "      <td>2024-05-07 23:51:29</td>\n",
       "      <td>48.53320</td>\n",
       "      <td>-6.12003</td>\n",
       "      <td>0.349444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    cog   sog  rot  heading  navstat              etaRaw  \\\n",
       "0 2024-05-08 00:03:16  179.6   0.0  0.0    344.0      5.0 2024-05-08 00:03:16   \n",
       "1 2024-05-08 00:06:17   24.7   0.0  0.0    214.0      5.0 2024-05-08 00:06:17   \n",
       "2 2024-05-08 00:10:02    8.0  18.7  0.0      6.0      0.0 2024-05-08 00:10:02   \n",
       "3 2024-05-08 00:10:34  321.3   0.1  0.0     70.0      1.0 2024-05-08 00:10:34   \n",
       "4 2024-05-08 00:12:27  291.0   0.3  0.0    275.0      2.0 2024-05-08 00:12:27   \n",
       "\n",
       "   latitude  longitude                  vesselId                    portId  \\\n",
       "0  0.111111   0.111111  61e9f3aeb937134a3c4bfe3d  61d371c43aeaecc07011a37f   \n",
       "1  0.111111   0.111111  61e9f473b937134a3c4c02df  61d371c43aeaecc07011a37f   \n",
       "2  0.111111   0.111111  61e9f469b937134a3c4c029b  61d371c43aeaecc07011a37f   \n",
       "3  0.111111   0.111111  61e9f45bb937134a3c4c0221  61d371c43aeaecc07011a37f   \n",
       "4  0.111111   0.111111  61e9f38eb937134a3c4bfd8d  61d371c43aeaecc07011a37f   \n",
       "\n",
       "               time_2  prev_lat   prev_lon  time_dif  \n",
       "0 2024-05-07 23:48:16  31.14647  -81.49789  0.250000  \n",
       "1 2024-05-07 23:57:16  14.81694  120.29625  0.150278  \n",
       "2 2024-05-07 23:59:08  38.27895   10.78280  0.181667  \n",
       "3 2024-05-07 23:52:34 -43.53785  172.83522  0.300000  \n",
       "4 2024-05-07 23:51:29  48.53320   -6.12003  0.349444  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction (test):\n",
    "    results = []\n",
    "    for i in range(len(test)):\n",
    "        pos = travel_predict(test.loc[i,['prev_lon']],test.loc[i,['prev_lat']],test.loc[i,['sog']],test.loc[i,['time_dif']],test.loc[i,['cog']])\n",
    "        results.append({'ID':i,'longitude_predicted':pos[0],'latitude_predicted':pos[1]})\n",
    "    pred = pd.Dataframe(results)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos = travel_predict(test.loc[i,['prev_lon']],test.loc[i,['prev_lat']],test.loc[i,['sog']],test.loc[i,['time_dif']],test.loc[i,['cog']])\n",
    "result =travel_predict_1(t)\n",
    "result=result.reset_index()\n",
    "result.rename(columns={'index': 'ID'}, inplace=True)\n",
    "result.to_csv('data/first_try.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the dates into a different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original['time'] = pd.to_datetime(X_original['time'])\n",
    "X_original['year'] = X_original['time'].dt.year\n",
    "X_original['month'] = X_original['time'].dt.month\n",
    "X_original['day'] = X_original['time'].dt.day\n",
    "X_original['hour'] = X_original['time'].dt.hour\n",
    "X_original['minute'] = X_original['time'].dt.minute\n",
    "X_original['second'] = X_original['time'].dt.second\n",
    "\n",
    "X_original['etaRaw'] = pd.to_datetime(X_original['etaRaw'], format='%m-%d %H:%M', errors='coerce')\n",
    "X_original['eta_month'] = X_original['etaRaw'].dt.month\n",
    "X_original['eta_day'] = X_original['etaRaw'].dt.day\n",
    "X_original['eta_hour'] = X_original['etaRaw'].dt.hour\n",
    "X_original['eta_minute'] = X_original['etaRaw'].dt.minute\n",
    "\n",
    "X_original = X_original.drop(['time','etaRaw'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to generate a merged dataset with the vessels (non functional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = pd.merge(X_train,extra_vessels, on='vesselId',how='left')\n",
    "prueba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into a train/test one and x-(all the info)  y-(the results longitud/latitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating one test file\n",
    "X_original = X_original.drop(['vesselId','portId'], axis=1)\n",
    "\n",
    "x_test=X_original.sample(frac=0.2, random_state=42)\n",
    "x_train=X_original.drop(x_test.index)\n",
    "\n",
    "y_test_lon=x_test.loc[:,['longitude']]\n",
    "y_test_lat=x_test.loc[:,['latitude']]\n",
    "x_test=x_test.drop(['longitude','latitude'],axis=1)\n",
    "\n",
    "y_train_lon=x_train.loc[:,['longitude']]\n",
    "y_train_lat=x_train.loc[:,['latitude']]\n",
    "x_train = x_train.drop(['longitude','latitude'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verification (length must match)\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test_lon shape: {y_test_lon.shape}\")\n",
    "print(f\"y_test_lat shape: {y_test_lat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating three sets of training data to train 3 different models\n",
    "#Split of the data in 3 equal slices\n",
    "x_original_1 = X_original.sample(frac=1/3, random_state=42)\n",
    "X_original_trans = X_original.drop(x_original_1.index)\n",
    "x_original_2 = X_original_trans.sample(frac=0.5, random_state=42)\n",
    "x_original_3 = X_original_trans.drop(x_original_2.index)\n",
    "\n",
    "#Adapting the slices into x and y\n",
    "#slice 1\n",
    "y_test_1_lon = x_original_1.loc[:,['longitude']]\n",
    "y_test_1_lat = x_original_1.loc[:,['latitude']]\n",
    "x_test_1 = x_original_1.drop(['longitude','latitude'],axis=1)\n",
    "x_train_1 = X_original.drop(x_original_1.index)\n",
    "y_train_1_lon = x_train_1.loc[:,['longitude']]\n",
    "y_train_1_lat = x_train_1.loc[:,['latitude']]\n",
    "x_train_1 = x_train_1.drop(['longitude','latitude'],axis=1)\n",
    "#slice 2\n",
    "y_test_2_lon=x_original_2.loc[:,['longitude']]\n",
    "y_test_2_lat=x_original_2.loc[:,['latitude']]\n",
    "x_test_2 = x_original_2.drop(['longitude','latitude'],axis=1)\n",
    "x_train_2 = X_original.drop(x_original_2.index)\n",
    "y_train_2_lon = x_train_2.loc[:,['longitude']]\n",
    "y_train_2_lat = x_train_2.loc[:,['latitude']]\n",
    "x_train_2 = x_train_2.drop(['longitude','latitude'],axis=1)\n",
    "#slice 3\n",
    "y_test_3_lon=x_original_3.loc[:,['longitude']]\n",
    "y_test_3_lat=x_original_3.loc[:,['latitude']]\n",
    "x_test_3 = x_original_3.drop(['longitude','latitude'],axis=1)\n",
    "x_train_3 = X_original.drop(x_original_3.index)\n",
    "y_train_3_lon = x_train_3.loc[:,['longitude']]\n",
    "y_train_3_lat = x_train_3.loc[:,['latitude']]\n",
    "x_train_3 = x_train_3.drop(['longitude','latitude'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_original shape: (1522065, 17)\n",
      "x_train_1 shape: (1014710, 15)\n",
      "y_train_1_lon shape: (1014710, 1)\n",
      "y_train_1_lat shape: (1014710, 1)\n",
      "x_test_1 shape: (507355, 15)\n",
      "y_test_1_lon shape: (507355, 1)\n",
      "y_test_1_lat shape: (507355, 1)\n"
     ]
    }
   ],
   "source": [
    "#verification (length must match)\n",
    "print(f\"X_original shape: {X_original.shape}\")\n",
    "print(f\"x_train_1 shape: {x_train_1.shape}\")\n",
    "print(f\"y_train_1_lon shape: {y_train_1_lon.shape}\")\n",
    "print(f\"y_train_1_lat shape: {y_train_1_lat.shape}\")\n",
    "print(f\"x_test_1 shape: {x_test_1.shape}\")\n",
    "print(f\"y_test_1_lon shape: {y_test_1_lon.shape}\")\n",
    "print(f\"y_test_1_lat shape: {y_test_1_lat.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a utility function to print out the prediction performance\n",
    "def evaluate_result(y_test, y_pred):\n",
    "    print(mean_absolute_error(y_test, y_pred))\n",
    "    print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model generation of random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "clf.fit(x_train, y_train_lon.values.ravel())\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.217318774346422\n",
      "0.7901448046453818\n"
     ]
    }
   ],
   "source": [
    "evaluate_result(y_test_lon,y_pred,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning for random forest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# model definition\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "# Search settings\n",
    "grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, \n",
    "                           cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# adjust the model\n",
    "grid_search.fit(x_train, y_train_lon)\n",
    "\n",
    "# see best parameters\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to build the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_merger(longitude,latitude):\n",
    "    submission = pd.merge(longitude, latitude, left_index=True, right_index=True, how='inner')\n",
    "    submission.insert(0, 'ID', range(len(df)))\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
